# Local LLM Chat

This is the web user interface for a local chat completion app for use with
LLMs running locally, as well as a persistent message and document embeddings
store using Postgres.

LLMs are run locally using [Ollama](https://ollama.ai).

